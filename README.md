## Part A: Supervised Fine-Tuning
I have fine-tune a variety of open-weight LLMs using Unsloth AI for different specialized tasks:

- **Llama 3.1 (8B)** â€“ Code generation & debugging assistant  
  ðŸ“„ [Colab Notebook](<your-colab-link-here>)  
- **Mistral NeMo (12B)** â€“ Customer-support chat agent  
  ðŸ“„ [Colab Notebook](<your-colab-link-here>)  
- **Gemma 2 (9B)** â€“ Human-like conversational AI  
  ðŸ“„ [Colab Notebook](<your-colab-link-here>)  
- **Phi-3 (medium)** â€“ Math-based reasoning & problem solving  
  ðŸ“„ [Colab Notebook](<your-colab-link-here>)  

## Part B: Continued Pretraining  
**Model:** TinyLlama (Hindi specialization)  
- **Purpose:** Adapt TinyLlama to handle Hindi text by unsupervised continuation of its language model pretraining.  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)

---

## Part C: Chat Template Showcase  
**Model:** TinyLlama  
- **Includes:**  
  - Text classification via chat prompts  
  - Multi-turn conversational examples  
  - Extended context window demonstrations  
  - Joint fine-tuning on multiple datasets  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)

---

## Part D: Preference-Based Reward Modeling  
**Model:** Phi-3 Mini  
- **Techniques:**  
  - Odds-Ratio Preference Optimization (ORPO)  
  - Direct Preference Optimization (DPO)  
- **Use Case:** Train the model to rank and prefer more helpful outputs.  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)

---

## Part E: Training from Checkpoint  
**Model:** TinyLlama  
- **Objective:** Demonstrate how to stop and restart fine-tuning from an intermediate checkpoint.  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)

---

## Part F: Mental-Health Support Chatbot  
**Model:** Phi-3 Mini  
- **Scope:** Fine-tune for empathetic, safe mental-health conversations, including dataset sourcing and safety filtering.  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)

---

## Part G: Export & Inference with Ollama  
**Model:** Llama 3  
- **Goal:** Convert your LoRA adapter into a GGUF format and run live inference via Ollama.  
- ðŸ“„ [Open in Colab](<your-colab-link-here>)


YouTube Demo explaning : 
